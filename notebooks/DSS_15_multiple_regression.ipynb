{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103a5d37-362d-4661-9e70-fc9ccce41748",
   "metadata": {},
   "source": [
    "# Multiple Regression\n",
    "\n",
    "## key concepts\n",
    "- For a slightly advanced model in the linear domain, we can add more variables (features) to our model.\n",
    "\n",
    "$$\n",
    "y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + \\alpha + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ = response (dependent) variable (response)\n",
    "- $x_{i1}, x_{i2}, x_{i3}$ = predictor variables\n",
    "- $\\beta_1$, $\\beta_2$, $\\beta_3$ = coefficients\n",
    "- $\\alpha$ = intercept\n",
    "- $\\varepsilon_i$ = error term (noise)\n",
    "\n",
    "> The $\\varepsilon_i$ can be understood in better detail as :\n",
    "> - Error term to represent that there are other factors not accounted for by this simple model.\n",
    "> - In 3b1b term, model is trying to do _book-keeping_. [Reference](https://youtu.be/9-Jl0dxWQs8?si=35nObUMC-FQVgPPh)\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4181436-f011-4660-9df4-66fd10e97d04",
   "metadata": {},
   "source": [
    "## Multiple Linear regression intuition\n",
    "\n",
    "- Model a response variable $y_i$ using multiple input features.\n",
    "\n",
    "### Model:\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_{i1} + ... + \\beta_k x_{ik} + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "#### In vector notation:\n",
    "\n",
    "$$\n",
    "y_i = \\mathbf{x}_i \\cdot \\boldsymbol{\\beta}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{x}i = [1, x_{i1}, x_{i2}, x_{i3}, .... x_{ik}]$ → input vector with a leading 1 for the intercept\n",
    "- $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1, \\beta_2, \\beta_3, ..., \\beta_k]$ → parameter vector (includes intercept)\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52d5dc0-fb21-4029-b203-e9a398ea8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed0b330-73a4-4994-a1d9-939956601fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from support.linear_algebra import dot, Vector\n",
    "\n",
    "def predict(x, beta):\n",
    "    \"\"\"Predicts y given input vector x and coeffecients beta.\n",
    "    Assumes x[0] is 1 for the intercept term.\n",
    "    \"\"\"\n",
    "\n",
    "    return dot(x, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8d4441-6219-4767-a11d-e5a7ab859c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = [1, 49, 4, 0] # [intercept, var-1, var-2, categorical variable 3]\n",
    "beta = [1.0, 1.5, -2.0, 3.0] # example weights\n",
    "\n",
    "predict(x_i, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501b88e-9ef3-41f0-bbf5-b5d62faab4b7",
   "metadata": {},
   "source": [
    "# Assumptions Behind Multiple Linear Regression (Least Squares)\n",
    "\n",
    "### For multiple regression to work correctly and give reliable estimates, two key assumptions must hold:\n",
    "\n",
    "1. No Perfect Multicollinearity\n",
    "\n",
    "> No predictor `(e.g., var-2)` should be an exact linear combination of other predictors (e.g., var-1, var-3, etc.).\n",
    "\n",
    "**Why is this important?**\n",
    "\n",
    "> If one variable can be formed exactly by combining others, the model can’t determine how much weight to assign to each.\n",
    "> It becomes impossible to uniquely estimate the coefficients.\n",
    "\n",
    "------------------\n",
    "\n",
    "2. No Correlation should exist b/w `Predictors` and `Errors`.\n",
    "\n",
    "The model assumes that the input variables are ***not*** correlated with the error terms.\n",
    "\n",
    "**Why does this matter?**\n",
    "> If this assumption fails, the model can systematically mis-estimate the coefficients.\n",
    "> Even if the predictors (features) look good individually, they may be indirectly masking the effect of others, leading to biased results.\n",
    "\n",
    "------------------\n",
    "\n",
    "#### Summary\n",
    "- Predictors should be independent from each other.\n",
    "- Predictors should also be independent from the errors.\n",
    "\n",
    "If these assumptions are not met, the model might still work, but the results will be misleading. Coefficients will not reflect the correct underlying relationships.\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f244d0ff-5c07-4c48-8e0f-ac987203a8c6",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "> choosing the `beta` to minimise the sum of squared errors.\n",
    "> *gradient descent* will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9435317-1495-4e0b-801b-72e2a3fe624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return predict(x, beta) - y \n",
    "\n",
    "def squared_error(x: Vector, y: float, beta: Vector) -> float:\n",
    "    return error(x, y, beta) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff199b89-f092-48ba-ab2d-a0323526c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3]\n",
    "y = 30\n",
    "beta = [4,4,4] # so prediction = 4+8+12=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3b9291-7828-42ff-9827-6a7e69db65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert error(x, y, beta) == -6\n",
    "assert squared_error(x, y, beta) == 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a16c67-3d03-45d8-95b0-cb9b06e05d62",
   "metadata": {},
   "source": [
    "### Formula Behind `sqerror_gradient`\n",
    "\n",
    "> The gradient of the squared error loss function wrt the parameter vector $\\boldsymbol{\\beta}$ is:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\beta} \\text{SE} = \\frac{\\partial}{\\partial \\beta} (y - \\hat{y})^2 = -2 (y - \\hat{y}) \\cdot \\mathbf{x}\n",
    "$$\n",
    "\n",
    "Or rewritten (since $\\hat{y} = \\mathbf{x} \\cdot \\boldsymbol{\\beta}$):\n",
    "\n",
    "$$\n",
    "\\nabla_{\\beta} \\text{SE} = 2 \\cdot (\\hat{y} - y) \\cdot \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e96b714-e1db-4719-883a-6e2c896ac790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using calculus\n",
    "\n",
    "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    err = error(x, y, beta)\n",
    "    return [2 * err * x_i for x_i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4428ba-6fed-49f4-93fc-7fab00abbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sqerror_gradient(x, y, beta) == [-12, -24, -36]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f7336-8618-45ca-86ef-8f249128e5d3",
   "metadata": {},
   "source": [
    "-----\n",
    "# Script Complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
